{"title":"Python爬虫","uid":"33e145189cb2c9be32b78fb749fd41d4","slug":"后端/Python/Python爬虫","date":"2022-08-30T03:30:00.000Z","updated":"2023-08-19T13:28:14.708Z","comments":true,"path":"api/articles/后端/Python/Python爬虫.json","keywords":null,"cover":"/images/cover/3.jpg","content":"<h1 id=\"Python爬虫\"><a href=\"#Python爬虫\" class=\"headerlink\" title=\"Python爬虫\"></a>Python爬虫</h1><h2 id=\"什么是爬虫\"><a href=\"#什么是爬虫\" class=\"headerlink\" title=\"什么是爬虫\"></a>什么是爬虫</h2><p><strong>通过编写程序，模拟浏览器上网，然后让其去互联网上抓取数据的过程。</strong></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>是一种自动获取网页数据信息的爬虫程序，是网站搜索引擎的重要组成部分。一般人能访问到的网页，爬虫也都能抓取。所谓的爬虫抓取，就是模拟人类访问目标网站。但和普通人访问方式不同，爬虫是可以按照一定的规则，自动的采集数据新。</p></blockquote>\n<h2 id=\"爬虫的价值\"><a href=\"#爬虫的价值\" class=\"headerlink\" title=\"爬虫的价值\"></a>爬虫的价值</h2><p><strong>在互联网中，数据是无价之宝，一切皆为数据，谁拥有大量有用 的数据，谁就拥有了决策的主动权。</strong>网络爬虫的应用领域很多，eg：爬取需要的数据进行统计、出行类软件可以利用爬虫抢票、整理聚合手机平台信息进行比较，数据分析、爬取个人信用信息。企业或政府利用爬取的数据，采用数据挖掘的相关方法，发掘用户讨论的内容、实行事件监测、舆情引导等。</p>\n<h2 id=\"爬虫的原理\"><a href=\"#爬虫的原理\" class=\"headerlink\" title=\"爬虫的原理\"></a>爬虫的原理</h2><p><strong>爬虫在使用场景中的分类分为以下4种。</strong></p>\n<ol>\n<li><p>通用网络爬虫</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>又称全网爬虫，爬取对象由一批种子URL扩充到整个Web，主要由搜索引擎或大型Web服务提供使商用。</p></blockquote>\n<p>抓取系统重要组成部分，抓取的是一整张页面的数据。</p>\n</li>\n<li><p>聚焦网络爬虫</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>又称主题网络爬虫，其最大的特点是只选择性地爬取与预设的主题相关的页面。</p></blockquote>\n<p>是建立在通用网络爬虫的基础之上的，抓取的是页面中特定的局部内容。</p>\n</li>\n<li><p>增量式网络爬虫</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>只对已经下载玩野采取增量式更新，或只怕去新产生的及已经发生变化的网页，这种机制能够在某种程度上保证爬取的页面尽可能的新。</p></blockquote>\n<p>检测网站中有数据更新的情况，只会抓取网站中最新更新出来的数据。</p>\n</li>\n<li><p>深层网络爬虫</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>指大部分内容无法通过静态链接获取，隐藏在表单后的，需要用户提交关键词后才能获得Web页面，如一些登录才可见的网页。</p></blockquote>\n</li>\n</ol>\n<h2 id=\"反爬机制\"><a href=\"#反爬机制\" class=\"headerlink\" title=\"反爬机制\"></a>反爬机制</h2><p>门户网站，可以通过制定相应的策略或者技术手段，防止爬虫程序进行网站数据的被爬取。</p>\n<h2 id=\"爬取策略\"><a href=\"#爬取策略\" class=\"headerlink\" title=\"爬取策略\"></a>爬取策略</h2><p>爬虫程序可以通过制定相关的策略或者技术手段，破解门户网站中具备的反爬机制，从而获取数据。</p>\n<h2 id=\"robots-txt协议\"><a href=\"#robots-txt协议\" class=\"headerlink\" title=\"robots.txt协议\"></a>robots.txt协议</h2><p>该协议不是一份规范，只是一个约定俗成的协议。爬虫应当遵守这份协议，否则很可能会被万丈所有者封禁IP，甚至网站所有者会采取进一步法律行动。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>著名的360的爬虫之争为案例</p></blockquote>\n<h2 id=\"http协议\"><a href=\"#http协议\" class=\"headerlink\" title=\"http协议\"></a>http协议</h2><p>就是服务器和客户端进行数据交互的一种形式。</p>\n<p>常用的请求偷头信息：</p>\n<ul>\n<li>User-Agent：请求载体身份标识。</li>\n<li>Connection：请求完毕后，是断开连接还是保持连接。</li>\n</ul>\n<p>常用响应头信息：</p>\n<ul>\n<li>Content-Type：服务器响应回客户端的数据类型。</li>\n</ul>\n<p>https协议：</p>\n<ul>\n<li>安全的超文本传输协议</li>\n</ul>\n<p>加密方式：</p>\n<ul>\n<li>对称秘钥加密</li>\n<li>非对称秘钥加密</li>\n<li>证书秘钥加密</li>\n</ul>\n<h1 id=\"requests模块\"><a href=\"#requests模块\" class=\"headerlink\" title=\"requests模块\"></a>requests模块</h1><h2 id=\"request模块是什么？\"><a href=\"#request模块是什么？\" class=\"headerlink\" title=\"request模块是什么？\"></a>request模块是什么？</h2><p>python中原生的一款基于网络请求的模块</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在python内置模块的基础上进行了高度的封装，从而使得python进行网络请求时，变得人性化，使用Requests可以轻而易举的完成浏览器可有的任何操作。</p></blockquote>\n<p>作用：模拟浏览器向服务器发请求。</p>\n<h2 id=\"requests的安装\"><a href=\"#requests的安装\" class=\"headerlink\" title=\"requests的安装\"></a>requests的安装</h2><pre class=\"line-numbers language-pip\" data-language=\"pip\"><code class=\"language-pip\">pip install requests</code></pre>\n\n<h2 id=\"http请求类型\"><a href=\"#http请求类型\" class=\"headerlink\" title=\"http请求类型\"></a>http请求类型</h2><p>有4种请求类型：</p>\n<ol>\n<li>PUT</li>\n<li>DELETE</li>\n<li>HEAD</li>\n<li>OPTIONS</li>\n</ol>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">requests.get(‘https:&#x2F;&#x2F;github.com&#x2F;timeline.json’)                                # GET请求\nrequests.post(“http:&#x2F;&#x2F;httpbin.org&#x2F;post”)                                        # POST请求\nrequests.put(“http:&#x2F;&#x2F;httpbin.org&#x2F;put”，data &#x3D; &#123;&#39;key&#39;:&#39;value&#39;&#125;)                  # PUT请求\nrequests.delete(“http:&#x2F;&#x2F;httpbin.org&#x2F;delete”)                                    # DELETE请求\nrequests.head(“http:&#x2F;&#x2F;httpbin.org&#x2F;get”)                                         # HEAD请求\nrequests.options(“http:&#x2F;&#x2F;httpbin.org&#x2F;get” )                                     # OPTIONS请求</code></pre>\n\n<h2 id=\"使用流程-x2F-编码流程\"><a href=\"#使用流程-x2F-编码流程\" class=\"headerlink\" title=\"使用流程&#x2F;编码流程\"></a>使用流程&#x2F;编码流程</h2><ol>\n<li>指定URL</li>\n<li>基于requests模块<strong>发送请求</strong></li>\n<li><strong>获取响应</strong>对象中的<strong>数据</strong>值</li>\n<li>持久化存储</li>\n</ol>\n<h1 id=\"第一个简单的爬虫程序\"><a href=\"#第一个简单的爬虫程序\" class=\"headerlink\" title=\"第一个简单的爬虫程序\"></a>第一个简单的爬虫程序</h1><p>使用request模块实现一个简单的网页采集。</p>\n<h2 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h2><h3 id=\"指定url\"><a href=\"#指定url\" class=\"headerlink\" title=\"指定url\"></a>指定url</h3><p>如下的问号其实可以保留也可以不保留。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">#指定url\nurl &#x3D; &#39;https:&#x2F;&#x2F;www.sogou.com&#x2F;web?&#39;</code></pre>\n\n\n\n<h3 id=\"User-Agent伪装\"><a href=\"#User-Agent伪装\" class=\"headerlink\" title=\"User-Agent伪装\"></a>User-Agent伪装</h3><p>这一步需要用浏览器在开发者工具中查看自己本机的User-Agent。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">#UA伪装\nheaders &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;x.x (Macintosh; Intel Mac OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x Safari&#x2F;xxx.xx&#39;\n&#125;</code></pre>\n\n\n\n<h3 id=\"响应发起请求\"><a href=\"#响应发起请求\" class=\"headerlink\" title=\"响应发起请求\"></a>响应发起请求</h3><p>get请求返回的是一个response响应对象。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">#获取请求响应\nresponse &#x3D; requests.get(url &#x3D; url,params &#x3D; param,headers &#x3D; headers) #get返回一个响应对象</code></pre>\n\n\n\n<h3 id=\"获取响应数据\"><a href=\"#获取响应数据\" class=\"headerlink\" title=\"获取响应数据\"></a>获取响应数据</h3><p>获取字符串形式的响应数据，也就是获取text的格式的响应数据。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">page_text &#x3D; response.text #获取字符串形式的响应数据</code></pre>\n\n\n\n<h3 id=\"持久化储存\"><a href=\"#持久化储存\" class=\"headerlink\" title=\"持久化储存\"></a>持久化储存</h3><p>这一步就是最后的操作了，把采集到的网页页面元素保存下来。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">with open(fileName,&#39;w&#39;,encoding &#x3D; &#39;utf-8&#39;) as fp:\n    fp.write(page_text)</code></pre>\n\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\n\n#指定url\nurl &#x3D; &#39;https:&#x2F;&#x2F;www.sogou.com&#x2F;web?&#39;\n#UA伪装\nheaders &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;x.x (Macintosh; Intel Mac OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x Safari&#x2F;xxx.xx&#39;\n&#125;\n\nkw &#x3D; input(&quot;请输入一个关键词: &quot;)\nparam &#x3D; &#123;\n    &#39;query&#39;:kw\n&#125;\nfileName &#x3D; kw+&#39;.html&#39;\n#获取请求响应\nresponse &#x3D; requests.get(url &#x3D; url,params &#x3D; param,headers &#x3D; headers) #get放回一个响应对象\npage_text &#x3D; response.text #获取字符串形式的响应数据\nwith open(fileName,&#39;w&#39;,encoding &#x3D; &#39;utf-8&#39;) as fp:\n    fp.write(page_text)\n\nprint(fileName,&#39;save successfully&#39;)\n</code></pre>\n\n\n\n<h1 id=\"某度翻译破解\"><a href=\"#某度翻译破解\" class=\"headerlink\" title=\"某度翻译破解\"></a>某度翻译破解</h1><p><strong>在pycharm中实现直接输入要翻译的英语单词，终获得翻译结果并且保存下来。</strong></p>\n<h2 id=\"指定url-1\"><a href=\"#指定url-1\" class=\"headerlink\" title=\"指定url\"></a>指定url</h2><p>利用浏览器的开发工具进行数据抓包，在XHP页面获取Ajax实际请求地址。</p>\n<p>切换到Headers找到请求，可以看到请求的url、请求方式和返回的数据类型都有了。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定url\nurl &#x3D; &#39;https:&#x2F;&#x2F;fanyi.baidu.com&#x2F;sug&#39;</code></pre>\n\n\n\n<h2 id=\"UA伪装\"><a href=\"#UA伪装\" class=\"headerlink\" title=\"UA伪装\"></a>UA伪装</h2><p><strong>让爬虫对应的请求载体身份标识伪装成某一款浏览器。</strong><br>方法：将对应的User-Agent封装到一个字典中。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># UA伪装\nheaders &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;x.x (Macintosh; Intel Mac OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x Safari&#x2F;xxx.xx&#39;\n&#125;</code></pre>\n\n\n\n<h2 id=\"POST请求参数处理\"><a href=\"#POST请求参数处理\" class=\"headerlink\" title=\"POST请求参数处理\"></a>POST请求参数处理</h2><p>在XHP页面获取Ajax实际相关参数。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># post请求参数处理（同get请求一致）\ndata &#x3D; &#123;\n    &#39;kw&#39;: words\n&#125;</code></pre>\n\n\n\n<h2 id=\"请求发送\"><a href=\"#请求发送\" class=\"headerlink\" title=\"请求发送\"></a>请求发送</h2><p>基于requests发送请求，通过前面抓包得到的信息我们得到了，它的请求方式为post请求，这里我们使用requests模块中post()方法来发送请求</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 请求发送\nresponce &#x3D; requests.post(url&#x3D;url, data&#x3D;data, headers&#x3D;headers)</code></pre>\n\n\n\n<h2 id=\"获取响应数据-1\"><a href=\"#获取响应数据-1\" class=\"headerlink\" title=\"获取响应数据\"></a>获取响应数据</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取响应数据：json()方法放回的是obj（确认了响应数据是json类型才可以用json()方法）\nresult &#x3D; responce.json()  # 返回一个obj</code></pre>\n\n\n\n<h2 id=\"进行持久化存储\"><a href=\"#进行持久化存储\" class=\"headerlink\" title=\"进行持久化存储\"></a>进行持久化存储</h2><p>默认使用的编码是ASCII（不包含中文），而中文是Unicode编码。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 进行持久化存储\nfp &#x3D; open(fileName, &#39;w&#39;, encoding&#x3D;&#39;UTF-8&#39;)\njson.dump(result, fp&#x3D;fp, ensure_ascii&#x3D;False)  # json()返回的obj中有中文 所以不能用ASCII解码</code></pre>\n\n\n\n<h2 id=\"完整代码-1\"><a href=\"#完整代码-1\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\nimport json\n\n# 指定url\nurl &#x3D; &#39;https:&#x2F;&#x2F;fanyi.baidu.com&#x2F;sug&#39;\n\n# UA伪装\nheaders &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;x.x (Macintosh; Intel Mac OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x Safari&#x2F;xxx.xx&#39;\n&#125;\n\n# 输入翻译的词\nwords &#x3D; input(&#39;请输入要翻译的英语单词: &#39;)\n# post请求参数处理（同get请求一致）\ndata &#x3D; &#123;\n    &#39;kw&#39;: words\n&#125;\n# 请求发送\nresponce &#x3D; requests.post(url&#x3D;url, data&#x3D;data, headers&#x3D;headers)\n\nfileName &#x3D; words + &#39;.json&#39;\n\n# 获取响应数据：json()方法放回的是obj（确认了响应数据是json类型才可以用json()方法）\nresult &#x3D; responce.json()  # 返回一个obj\nprint(&#39;翻译结果如下:&#39;)\nprint(result)  # 打印返回的obj结果\n\n# 进行持久化存储\nfp &#x3D; open(fileName, &#39;w&#39;, encoding&#x3D;&#39;UTF-8&#39;)\njson.dump(result, fp&#x3D;fp, ensure_ascii&#x3D;False)  # json()返回的obj中有中文 所以不能用ASCII解码\nprint(&#39;save over！&#39;)\n</code></pre>\n\n\n\n<h1 id=\"正则表达式模块\"><a href=\"#正则表达式模块\" class=\"headerlink\" title=\"正则表达式模块\"></a>正则表达式模块</h1><p><strong>Python通过自带的re模块来支持正则表达式</strong></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><ol>\n<li>先将正则表达式的String编译为“Pattern”实例</li>\n<li>使用Pattern实例处理结文本并且获得匹配结果（一个Match实例）</li>\n<li>使用Match实例获得信息</li>\n</ol></blockquote>\n<h2 id=\"re模块常用的方法\"><a href=\"#re模块常用的方法\" class=\"headerlink\" title=\"re模块常用的方法\"></a>re模块常用的方法</h2><table>\n<thead>\n<tr>\n<th align=\"left\">方法名</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">compile</td>\n<td align=\"left\">将正则表达式String转化为Pattern匹配对象。</td>\n</tr>\n<tr>\n<td align=\"left\">match</td>\n<td align=\"left\">将输入的String从头开始对输入的正则表达式进行匹配，如果遇到无法匹配的字符或到达String的末尾，则立即放回None，否则获取匹配结果。</td>\n</tr>\n<tr>\n<td align=\"left\">search</td>\n<td align=\"left\">将输入的整个String进行扫描，对输入的正则表达式进行匹配，并获取匹配结果，如果没有匹配结果，则返回None。</td>\n</tr>\n<tr>\n<td align=\"left\">split</td>\n<td align=\"left\">以能够匹配的String作为分隔符，将String分割后返回一个列表。</td>\n</tr>\n<tr>\n<td align=\"left\">findall</td>\n<td align=\"left\">搜索整个String，返回一个包含全部能匹配子串的列表。</td>\n</tr>\n<tr>\n<td align=\"left\">finditer</td>\n<td align=\"left\">与findall方法的作用类似，以迭代器的形式返回结果。</td>\n</tr>\n<tr>\n<td align=\"left\">sub</td>\n<td align=\"left\">使用指定内容替换字符串中匹配的每一个子串内容。</td>\n</tr>\n</tbody></table>\n<h3 id=\"compile方法\"><a href=\"#compile方法\" class=\"headerlink\" title=\"compile方法\"></a>compile方法</h3><p><strong>将正则表达式的字符串转化为Pattern匹配对象</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">re.compile(pattern,flags&#x3D;0)</code></pre>\n\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pattern</td>\n<td>接收str，表示需要转换的正则表达式的字符串。无默认值。</td>\n</tr>\n<tr>\n<td>flags</td>\n<td>接收str，表示匹配的模式，取值为运算符”|”时表示同时生效，如re.I|re.M。默认为0。</td>\n</tr>\n</tbody></table>\n<h3 id=\"search方法\"><a href=\"#search方法\" class=\"headerlink\" title=\"search方法\"></a>search方法</h3><p><strong>该方法将输入的整个字符串进行扫描，并对输入的正则表达式进行匹配，若无匹配的字符，则立即返回None，否则获取匹配结果。</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">re.search(pattern,string,flags&#x3D;0)</code></pre>\n\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pattern</td>\n<td>接收Pattern实例，表示转换后的正则表达式。无默认值。</td>\n</tr>\n<tr>\n<td>string</td>\n<td>接收str，表示输入的需要匹配的字符串。无默认值。</td>\n</tr>\n<tr>\n<td>flags</td>\n<td>接收str，表示匹配的模式，取值为运算符”|”时表示同时生效。</td>\n</tr>\n</tbody></table>\n<h3 id=\"finall方法\"><a href=\"#finall方法\" class=\"headerlink\" title=\"finall方法\"></a>finall方法</h3><p><strong>该方法搜索整个string，并放回一个包含所有能匹配的子串的列表</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">re.finall(pattern,string,flags&#x3D;0)</code></pre>\n\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pattern</td>\n<td>接收Pattern实例，表示转换后的正则表达式。无默认值。</td>\n</tr>\n<tr>\n<td>string</td>\n<td>接收str，表示输入的需要匹配的字符串。无默认值。</td>\n</tr>\n<tr>\n<td>flags</td>\n<td>接收str，表示匹配的模式，取值为运算符”|”时表示同时生效，意思为“or”。</td>\n</tr>\n</tbody></table>\n<p><strong>使用finall方法找出字符串中的所有数字</strong></p>\n<p>若 str &#x3D; a1b2c3d4e5f6g7 找出其中的所有数字：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import re\n\npat &#x3D; re.compile(r&#39;\\d+&#39;)\nstr &#x3D; &#39;a1b2c3d4e5f6g7&#39;\t#设定：str &#x3D; a1b2c3d4e5f6g7\nresult &#x3D; re.findall(pat, str)\nprint(result)   #输出：[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;]</code></pre>\n\n\n\n<h2 id=\"获取网页中的标题内容\"><a href=\"#获取网页中的标题内容\" class=\"headerlink\" title=\"获取网页中的标题内容\"></a>获取网页中的标题内容</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import re\nimport requests\n\nurl &#x3D; &#39;http:&#x2F;&#x2F;www.tipdm.com&#x2F;tipdm&#x2F;index.html&#39;\n\nheader &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Macintosh; Intel xxx OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x xxxxx&#x2F;xxx.xx&#39;,\n    &#39;Cookie&#39;: &#39;_site_id_cookie&#x3D;xx; _site_id_cookie&#x3D;xx.x; JSESSIONID&#x3D;abcdefg123456abcd1234; clientlanguage&#x3D;zh_CN&#39;\n&#125;\nrequests_get &#x3D; requests.get(url, header)\nrequests_get.encoding &#x3D; &#39;utf-8&#39;\nhtml_text &#x3D; requests_get.text\n\n# &lt;title&gt;泰迪科技-专注于大数据技术研发及知识传播&lt;&#x2F;title&gt;\npattern &#x3D; r&#39;(?&lt;&#x3D;&lt;title&gt;).*?(?&#x3D;&lt;&#x2F;title&gt;)&#39;\nresult_com &#x3D; re.compile(pattern)\nresult_search &#x3D; re.search(result_com, html_text)\n# &lt;re.Match object; span&#x3D;(178, 198), match&#x3D;&#39;泰迪科技-专注于大数据技术研发及知识传播&#39;&gt;\nprint(result_search)\n# 泰迪科技-专注于大数据技术研发及知识传播\nprint(result_search.group())</code></pre>\n\n<p><strong>一步到位</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import re\nimport requests\n\nurl &#x3D; &#39;http:&#x2F;&#x2F;www.tipdm.com&#x2F;tipdm&#x2F;index.html&#39;\nheader &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Macintosh; Intel xxx OS X xx_xx_x) AppleWebKit&#x2F;xxx.xx (KHTML, like Gecko) Chrome&#x2F;xxx.x.x.x xxxxx&#x2F;xxx.xx&#39;,\n    &#39;Cookie&#39;: &#39;_site_id_cookie&#x3D;xx; _site_id_cookie&#x3D;xx.x; JSESSIONID&#x3D;abcdefg123456abcd1234; clientlanguage&#x3D;zh_CN&#39;\n&#125;\nrequests_get &#x3D; requests.get(url, header)\n# requests_get.encoding &#x3D; &#39;utf-8&#39;\nhtml_text &#x3D; requests_get.text\n# &lt;title&gt;泰迪科技-专注于大数据技术研发及知识传播&lt;&#x2F;title&gt;\nprint(re.findall(r&#39;(?&lt;&#x3D;&lt;title&gt;).*?(?&#x3D;&lt;&#x2F;title&gt;)&#39;, html_text))</code></pre>\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>其实不推荐使用正则表达式去定位特定节点来获得其中想要的内容的。</p>\n<p>✅推荐使用：Xpath、BeautifulSoup。</p></blockquote>\n<h1 id=\"使用Xpath解析网页\"><a href=\"#使用Xpath解析网页\" class=\"headerlink\" title=\"使用Xpath解析网页\"></a>使用Xpath解析网页</h1><p><strong>XML路径语言（XML Path Language，Xpath）</strong>是一门文档中查找信息的语言。</p>\n<h2 id=\"基础语法\"><a href=\"#基础语法\" class=\"headerlink\" title=\"基础语法\"></a>基础语法</h2><p>使用Xpath需要从lxml库中导入etree模块，还需要使用HTML类对需要匹配的HTML对象进行初始化。HTML类对基本语法格式如下：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">lxml.etree.HTML(text, parser&#x3D;None, *, base_url&#x3D;None)</code></pre>\n\n<p><strong>HTML类对常用参数及说明如下：</strong></p>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>text</strong></td>\n<td>接收str 表示需要转换为HTML的字符串。无默认值</td>\n</tr>\n<tr>\n<td><strong>parser</strong></td>\n<td>接收str 表示选择的HTML解析器。无默认值</td>\n</tr>\n<tr>\n<td><strong>base_url</strong></td>\n<td>接收str 表示文档的原始URL 用于查找外部实体的相对路径。默认为None</td>\n</tr>\n</tbody></table>\n<p><strong>Xpath可以使用类似正则的表达式来匹配HTML文件中的内容，常用的表达式如下：</strong></p>\n<table>\n<thead>\n<tr>\n<th>表达式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>nodename</strong></td>\n<td>选取nodename节点的所有子节点</td>\n</tr>\n<tr>\n<td><strong>&#x2F;</strong></td>\n<td>从当前节点选取直接子节点</td>\n</tr>\n<tr>\n<td><strong>&#x2F;&#x2F;</strong></td>\n<td>从当前节点选取所有子孙节点</td>\n</tr>\n<tr>\n<td><strong>.</strong></td>\n<td>选取当前节点</td>\n</tr>\n<tr>\n<td><strong>..</strong></td>\n<td>选取当前节点的父节点</td>\n</tr>\n<tr>\n<td><strong>@</strong></td>\n<td>选取属性</td>\n</tr>\n</tbody></table>\n<h2 id=\"谓语\"><a href=\"#谓语\" class=\"headerlink\" title=\"谓语\"></a>谓语</h2><p>Xpath中的谓语可用来查找某个特定的节点或包含某个指定的值的节点，谓语呗嵌套在路径后面的方括号中，如下：</p>\n<table>\n<thead>\n<tr>\n<th>表达式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[1]</td>\n<td>选取属于body子节点的第一个的div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[last()]</td>\n<td>选取属于body子节点的最后一个div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[last()-1]</td>\n<td>选取属于body子节点的倒数第二个div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[postion()&lt;3]</td>\n<td>选取属于body子节点的前两个div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[@id]</td>\n<td>选取属于body子节点的带有id属性的div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[@id&#x3D;”content”]</td>\n<td>选取属于body子节点的的id属性值为content的div节点</td>\n</tr>\n<tr>\n<td>&#x2F;html&#x2F;boby&#x2F;div[xx&gt;10.00]</td>\n<td>选取属于body子节点的body子节点的xx元素值大于10的节点</td>\n</tr>\n</tbody></table>\n<h2 id=\"完整代码-2\"><a href=\"#完整代码-2\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><p><strong>请运用所学Xpath方法，试着爬取<a href=\"https://s.weibo.com/top/summary\">微博</a>的热搜关键词。</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import re\nimport requests\nfrom lxml import etree\n</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定url\nurl &#x3D; &#39;https:&#x2F;&#x2F;s.weibo.com&#x2F;top&#x2F;summary&#39;\n\n# user-agent伪装\nheader &#x3D; &#123;\n    &#39;user-agent&#39;:&#39;xxxxxxxxxxxxxx&#39;,\n    &#39;cookie&#39;:&#39;xxxxxxxxxxx&#39;\n&#125;</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">requests_get &#x3D; requests.get(url&#x3D;url,headers&#x3D;header)\nhtml &#x3D; requests_get.content.decode(&#39;utf-8&#39;)\n\nhtml &#x3D; etree.HTML(html,parser&#x3D;etree.HTMLParser(encoding&#x3D;&#39;utf-8&#39;))\nhtml</code></pre>\n\n<p><strong>&lt;Element html at 0x7fd20ac93f00&gt;</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">result &#x3D; html.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;pl_top_realtimehot&quot;]&#x2F;table&#x2F;tbody&#x2F;tr[1]&#x2F;td[2]&#x2F;a&#x2F;text()&#39;)\nresult</code></pre>\n\n<p><strong>[‘新闻发布会’]</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># divs &#x3D; html.xpath(&#39;&#x2F;html&#x2F;body&#x2F;div[1]&#x2F;div[2]&#x2F;div&#x2F;div[2]&#x2F;div[1]&#x2F;table&#x2F;tbody&#x2F;&#39;)\n# dics &#x3D; html.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;pl_top_realtimehot&quot;]&#x2F;table&#x2F;tbody&#x2F;tr&#x2F;td&#x2F;a&#39;)\ndivs &#x3D; html.xpath(&#39;&#x2F;html&#x2F;body&#x2F;div&#x2F;div&#x2F;div&#x2F;div&#x2F;div&#x2F;table&#x2F;tbody&#x2F;tr&#x2F;td&#x2F;a&#39;)\ni &#x3D; 1\nfor div in divs:\n    print(&quot;第&#123;&#125;条&quot;.format(i),div.text)\n    i+&#x3D;1</code></pre>\n\n<p><strong>第1条 新闻发布会</strong><br><strong>…</strong><br><strong>第19条 LGD</strong><br><strong>第20条 将盆栽越坐越歪的猫咪</strong><br><strong>第21条 活得还没10后小朋友明白</strong><br><strong>第22条 林志颖车祸后首次露面</strong><br><strong>第23条 哄睡师包月套餐标价1.8万</strong><br><strong>第24条 内娱国风氛围感大赏</strong><br>第25条 王一博骑摩托艇把街舞导演甩水里了**</p>\n<h1 id=\"使用Beautiful-Soup库解析网页\"><a href=\"#使用Beautiful-Soup库解析网页\" class=\"headerlink\" title=\"使用Beautiful Soup库解析网页\"></a>使用Beautiful Soup库解析网页</h1><p><strong>Beautiful Soup 是一个可以从HTML 或 XML 文件中提取数据的python库</strong></p>\n<h2 id=\"完整代码-3\"><a href=\"#完整代码-3\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\nfrom bs4 import BeautifulSoup\nfrom lxml import etree</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">header &#x3D; &#123;\n    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;x.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;xxxxxx (KHTML, like Gecko) Chrome&#x2F;90.0.4430.85 Safari&#x2F;xxx.36 Edg&#x2F;9x.0.xxxx.x6&#39;,\n    &#39;Cookie&#39;: &quot;SUB&#x3D;_2AkMUH_xxxxxxxxx-yT9jqm8GtRB6P5_ZTJnjeloNEw4vOcUYn5Ft-q_jepMk; SUBP&#x3D;0033WrSXqPxfM72-Ws9jqgMF5xxxxxxxxoQ4SDwJCdCGAo7QWv7g; _s_tentry&#x3D;passport.weibo.com; Apache&#x3D;9820xxxxxxxxx9.3xx.166xxxxxxx5834; SINAGLOBAL&#x3D;9820789867589.398.1xxxxxx5834; ULV&#x3D;166xxxxxx835:1:1:1:98207xxxxx589.398.1665366xxxxx4:&quot;&#125;\nres &#x3D; requests.get(&quot;https:&#x2F;&#x2F;s.weibo.com&#x2F;top&#x2F;summary&quot;, headers&#x3D;header)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">soup &#x3D; BeautifulSoup(res.text)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">dom &#x3D; etree.HTML(str(soup))\nhot_titles &#x3D; dom.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;pl_top_realtimehot&quot;]&#x2F;table&#x2F;tbody&#x2F;tr&#x2F;td&#x2F;a&#39;)\nfor i, v in enumerate(hot_titles):\n    print(i, v.text)</code></pre>\n\n<p><strong>0 xxxx大会</strong><br><strong>1 商场回应影院不让带蜜雪冰城</strong><br><strong>2 PDD已起诉多人侵犯名誉权</strong><br><strong>3 中国人的书信有多美</strong><br><strong>4 韩剧继承者们首播9周年</strong><br><strong>5 iPhone14车祸检测坐过山车会报警</strong><br><strong>6 教育局回应中学收20元树叶费</strong><br><strong>7 抑郁症不是简单的坏心情</strong><br><strong>8 普京称克里米亚大桥爆炸是恐怖主义行为</strong><br><strong>9 男孩得胃病竟因妈妈染幽门螺杆菌</strong><br><strong>10 未来三个月17.1%受访居民打算购房</strong><br><strong>11 RNG对战CFO</strong><br><strong>12 爱的二八定律出品方没有嘉行</strong><br><strong>13 内蒙古增本土确诊119例无症状559例</strong><br><strong>14 苏炳添再次起诉新东方子公司侵权</strong><br><strong>15 女子吐槽丈夫脑袋掉色枕头焦黄</strong><br><strong>16 女子路边发现80年代供销社</strong><br><strong>17 RNG战胜CFO</strong></p>\n<h1 id=\"使用post请求方法实现登录\"><a href=\"#使用post请求方法实现登录\" class=\"headerlink\" title=\"使用post请求方法实现登录\"></a>使用post请求方法实现登录</h1><p><strong>post请求方法能够保障用户端提交数据的安全性，因此被一般需要登录的完整所采用。requests库的post函数能够以post请求方法向服务器发送请求，返回一个Response<Respinse>对象</strong></p>\n<h2 id=\"完整代码-4\"><a href=\"#完整代码-4\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\nimport matplotlib.pyplot as plt</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># requests.post(url,data&#x3D;,json&#x3D;,**kwargs)\nurl &#x3D; &#39;http:&#x2F;&#x2F;www.ptpress.com.cn&#x2F;login&#39;\n# username: xxxxxxxxxx\n# password: xxxxxxxxxx\n# verifyCode: \ncode_url &#x3D; &#39;https:&#x2F;&#x2F;www.ptpress.com.cn&#x2F;kaptcha.jpg&#39; #验证码</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">#Session会话\nsess &#x3D; requests.Session()\nrq_code &#x3D; sess.get(code_url)    #对验证码的页面进行请求发送\nwith open(&#39;.&#x2F;captcha.jpg&#39;,&#39;wb&#39;) as fp:\n    fp.write(rq_code.content)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def get_code(): \n    pic &#x3D; plt.imread(&#39;.&#x2F;captcha.jpg&#39;)\n    plt.imshow(pic)\n    plt.show()\n    return input(&#39;请输入验证码&gt;&gt;&gt;&#39;)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">code &#x3D; get_code()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">login_data &#x3D; &#123;&#39;username&#39;:&#39;xxxxxxxxxxx&#39;,&#39;password&#39;:&#39;xxxxxxxxxxx&#39;,&#39;verifyCode&#39;:code&#125;\nlogin_data</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">rq &#x3D; sess.post(url,data&#x3D;login_data)</code></pre>\n\n<p><strong>最后一步验证是否成功：<a href=\"https://www.ptpress.com.cn/login%EF%BC%9A\">https://www.ptpress.com.cn/login：</a></strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">print(rq.url)</code></pre>\n\n","text":"📒 这篇笔记是关于自动获取网页数据信息的爬虫程序，是网站搜索引擎的重要组成部分。一般人能访问到的网页，爬虫也都能抓取。所谓的爬虫抓取，就是模拟人类访问目标网站。但和普通人访问方式不同，爬虫是可以按照一定的规则，自动的采集数据新。","link":"","photos":[],"count_time":{"symbolsCount":"14k","symbolsTime":"12 mins."},"categories":[{"name":"计算机","slug":"计算机","count":6,"path":"api/categories/计算机.json"},{"name":"后端","slug":"计算机/后端","count":2,"path":"api/categories/计算机/后端.json"}],"tags":[{"name":"笔记","slug":"笔记","count":8,"path":"api/tags/笔记.json"},{"name":"Python","slug":"Python","count":1,"path":"api/tags/Python.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Python%E7%88%AC%E8%99%AB\"><span class=\"toc-text\">Python爬虫</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF%E7%88%AC%E8%99%AB\"><span class=\"toc-text\">什么是爬虫</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%88%AC%E8%99%AB%E7%9A%84%E4%BB%B7%E5%80%BC\"><span class=\"toc-text\">爬虫的价值</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%88%AC%E8%99%AB%E7%9A%84%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">爬虫的原理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%8D%E7%88%AC%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">反爬机制</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%88%AC%E5%8F%96%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">爬取策略</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#robots-txt%E5%8D%8F%E8%AE%AE\"><span class=\"toc-text\">robots.txt协议</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#http%E5%8D%8F%E8%AE%AE\"><span class=\"toc-text\">http协议</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#requests%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">requests模块</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#request%E6%A8%A1%E5%9D%97%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">request模块是什么？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#requests%E7%9A%84%E5%AE%89%E8%A3%85\"><span class=\"toc-text\">requests的安装</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#http%E8%AF%B7%E6%B1%82%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">http请求类型</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B-x2F-%E7%BC%96%E7%A0%81%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">使用流程&#x2F;编码流程</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F\"><span class=\"toc-text\">第一个简单的爬虫程序</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%AD%A5%E9%AA%A4\"><span class=\"toc-text\">步骤</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8C%87%E5%AE%9Aurl\"><span class=\"toc-text\">指定url</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#User-Agent%E4%BC%AA%E8%A3%85\"><span class=\"toc-text\">User-Agent伪装</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%93%8D%E5%BA%94%E5%8F%91%E8%B5%B7%E8%AF%B7%E6%B1%82\"><span class=\"toc-text\">响应发起请求</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96%E5%93%8D%E5%BA%94%E6%95%B0%E6%8D%AE\"><span class=\"toc-text\">获取响应数据</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8C%81%E4%B9%85%E5%8C%96%E5%82%A8%E5%AD%98\"><span class=\"toc-text\">持久化储存</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">完整代码</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%9F%90%E5%BA%A6%E7%BF%BB%E8%AF%91%E7%A0%B4%E8%A7%A3\"><span class=\"toc-text\">某度翻译破解</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8C%87%E5%AE%9Aurl-1\"><span class=\"toc-text\">指定url</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#UA%E4%BC%AA%E8%A3%85\"><span class=\"toc-text\">UA伪装</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#POST%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86\"><span class=\"toc-text\">POST请求参数处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%B7%E6%B1%82%E5%8F%91%E9%80%81\"><span class=\"toc-text\">请求发送</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96%E5%93%8D%E5%BA%94%E6%95%B0%E6%8D%AE-1\"><span class=\"toc-text\">获取响应数据</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E8%A1%8C%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8\"><span class=\"toc-text\">进行持久化存储</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-1\"><span class=\"toc-text\">完整代码</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">正则表达式模块</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#re%E6%A8%A1%E5%9D%97%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">re模块常用的方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#compile%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">compile方法</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#search%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">search方法</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#finall%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">finall方法</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E4%B8%AD%E7%9A%84%E6%A0%87%E9%A2%98%E5%86%85%E5%AE%B9\"><span class=\"toc-text\">获取网页中的标题内容</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8Xpath%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5\"><span class=\"toc-text\">使用Xpath解析网页</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95\"><span class=\"toc-text\">基础语法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%B0%93%E8%AF%AD\"><span class=\"toc-text\">谓语</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-2\"><span class=\"toc-text\">完整代码</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8Beautiful-Soup%E5%BA%93%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5\"><span class=\"toc-text\">使用Beautiful Soup库解析网页</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-3\"><span class=\"toc-text\">完整代码</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8post%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%99%BB%E5%BD%95\"><span class=\"toc-text\">使用post请求方法实现登录</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-4\"><span class=\"toc-text\">完整代码</span></a></li></ol></li></ol>","author":{"name":"Honman","slug":"blog-author","avatar":"/images/avatar.jpeg","link":"/","description":"这家伙很坏 什么都没留下","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Vue基础入门","uid":"3a13b25df3ae48dbca78c649405861eb","slug":"前端/Vue/Vue基础入门","date":"2022-09-01T13:30:00.000Z","updated":"2023-08-19T13:26:14.627Z","comments":true,"path":"api/articles/前端/Vue/Vue基础入门.json","keywords":null,"cover":"/images/cover/4.jpg","text":"📒 Vue读音类似View，是一套用于构建用户界面的渐进式框架与其他大型框架（Angular、React...）相比,Vue被设计为可以自底向上逐层应用。而其他大型框架需要一开始就对项目的技术方案进行强制性的要求，Vue则更灵活，我们既可以选择Vue来开发一个全新项目，也可以将Vue引入到一个现有的项目中。","link":"","photos":[],"count_time":{"symbolsCount":"1.7k","symbolsTime":"2 mins."},"categories":[{"name":"计算机","slug":"计算机","count":6,"path":"api/categories/计算机.json"},{"name":"前端","slug":"计算机/前端","count":3,"path":"api/categories/计算机/前端.json"}],"tags":[{"name":"笔记","slug":"笔记","count":8,"path":"api/tags/笔记.json"},{"name":"Vue","slug":"Vue","count":1,"path":"api/tags/Vue.json"}],"author":{"name":"Honman","slug":"blog-author","avatar":"/images/avatar.jpeg","link":"/","description":"这家伙很坏 什么都没留下","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"MarkDown语法📖","uid":"88e8bb0bfdbc895aed5ccb8b7148e21d","slug":"语法篇/MarkDown语法","date":"2022-08-14T18:28:00.000Z","updated":"2023-08-19T13:30:39.259Z","comments":true,"path":"api/articles/语法篇/MarkDown语法.json","keywords":null,"cover":"/images/cover/6.jpg","text":"📒 这篇笔记是为了告诉你如何使用MarkDown的语法，涵盖了使用技巧，如果后期忘记了关于MarkDown的相关技巧不妨点进来复习查看。","link":"","photos":[],"count_time":{"symbolsCount":598,"symbolsTime":"1 mins."},"categories":[{"name":"计算机","slug":"计算机","count":6,"path":"api/categories/计算机.json"}],"tags":[{"name":"语法","slug":"语法","count":1,"path":"api/tags/语法.json"},{"name":"笔记","slug":"笔记","count":8,"path":"api/tags/笔记.json"}],"author":{"name":"Honman","slug":"blog-author","avatar":"/images/avatar.jpeg","link":"/","description":"这家伙很坏 什么都没留下","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}